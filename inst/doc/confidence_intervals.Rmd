---
title: "Notes on Confidence Intervals"
author: "Brad Cannell"
date: "Created: 2017-12-28 <br> Updated: `r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{confidence_intervals}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<style>
  hr 
  {
    background-color: #66b3ff;
    height: 1px;
  }
  blockquote
  {
    font-size: 12pt;
    font-style: italic;
    border-left: 4px solid #66b3ff;
  }
</style>

```{r setup, include = FALSE}
Sys.setenv(TZ = "US/Central")
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

-------------------------------------------------------------------------------

# Bottom Line

Give the point estimate along with the 95% confidence interval. Say NOTHING about statistical significance. 

Perhaps, write some kind of statement about the data's compatability with the model. 

For example, the confidence limits, however, indicate that these data, although statistically compatible with no association, are even more compatible with a strong association — assuming that the statistical model used to construct the limits is correct.

-------------------------------------------------------------------------------

# Rationale 

> We use confidence intervals because a point estimate, being a single value, cannot express the statistical variation, or random error, that underlies the estimate.

Rothman, Kenneth J.. Epidemiology: An Introduction (p. 149). Oxford University Press. Kindle Edition. 



-------------------------------------------------------------------------------

# Interpretation of confidence intervals

The following are frequentist interpretations for 95% confidence intervals taken from relevant texts and peer-reviewed journal articles.

**Biostatistics: A foundation for analysis in the health sciences**

> In repeated sampling, from a normally distributed population with a known standard deviation, 95% of all intervals will in the long run include the populations mean.

Daniel, W. W., & Cross, C. L. (2013). Biostatistics: A foundation for analysis in the health sciences (Tenth). Hoboken, NJ: Wiley.

This is a basic, frequentist statistical definition. It leaves out accompanying assumptions. See Rothman for details.

&nbsp;

**Epidemiology: An introduction**

> The confidence interval is defined statistically as follows: If the level of confidence is set to 95%, it means that if the data collection and analysis could be replicated many times and the study were free of bias, the confidence interval would include within it the correct value of the measure 95% of the time. This definition presumes that the only thing that would differ in these hypothetical replications of the study would be the statistical, or chance, element in the data. It also presumes that the variability in the data can be described adequately by a statistical model and that biases such as confounding are nonexistent or completely controlled. These unrealistic conditions are typically not met even in carefully designed and conducted randomized trials.

Rothman, Kenneth J. Epidemiology: An Introduction (p. 150). Oxford University Press. Kindle Edition.

This is also a frequentist statistical definition, but it includes accompanying assumptions.

> In nonexperimental epidemiologic studies, the formal definition of a confidence interval is a fiction that at best provides a rough estimate of the statistical variability in a set of data. It is better not to consider a confidence interval to be a literal measure of statistical variability but rather a general guide to the amount of random error in the data.

Rothman, Kenneth J.. Epidemiology: An Introduction (p. 150). Oxford University Press. Kindle Edition. 

Rothman and others use this kind of vague language about interpretation of confidence intervals. When you go read non-methodological papers that he is on, the confidence intervals are given, but basically just aren't interpreted.

&nbsp;

**Fundamentals of biostatistics**

> You may be puzzled at this point as to what a CI is. The parameter µ is a fixed unknown constant. How can we state that the probability that it lies within some specific interval is, for example, 95%? The important point to understand is that the boundaries of the interval depend on the sample mean and sample variance and vary from sample to sample. Furthermore, 95% of such intervals that could be constructed from repeated random samples of size n contain the parameter µ.

> The idea is that over a large number of hypothetical samples of size 10, 95% of such intervals contain the parameter µ. Any one interval from a particular sample may or may not contain the parameter µ. In Figure 6.7, by chance all five intervals contain the parameter µ. However, with additional random samples this need not be the case. Therefore, we cannot say there is a 95% chance that the parameter µ will fall within a particular 95% CI. **However, we can say the following: The length of the CI gives some idea of the precision of the point estimate x. In this particular case, the length of each CI ranges from 20 to 47 oz, which makes the precision of the point estimate x doubtful** and implies that a larger sample size is needed to get a more precise estimate of µ.

Rosner, B. (2015). Fundamentals of biostatistics (Eighth). MA: Cengage Learning.

&nbsp;

**Greenland, 2016**

[Link to misinterpretations](https://link.springer.com/article/10.1007/s10654-016-0149-3)

> The specific 95% confidence interval presented by a study has a 95% chance of containing the true effect size. No! A reported confidence interval is a range between two numbers. The frequency with which an observed interval (e.g., 0.72–2.88) contains the true effect is either 100% if the true effect is within the interval or 0% if not; the 95% refers only to how often 95% confidence intervals computed from very many studies would contain the true size if all the assumptions used to compute the intervals were correct.

> The 95% confidence intervals from two subgroups or studies may overlap substantially and yet the test for difference between them may still produce P < 0.05. Suppose for example, two 95% confidence intervals for means from normal populations with known variancesare (1.04, 4.96) and (4.16, 19.84); these intervals overlap, yet the test of the hypothesis of no difference in effect across studies gives P = 0.03. As with P values, comparison between groups requires statistics that directly test and estimate the differences across groups. It can, however, be noted that if the two 95 % confidence intervals fail to overlap, then when using the same assumptions used to compute the confidence intervals we will find P > 0.05 for the difference; and if one of the 95% intervals contains the point estimate from the other group or study, we will find P > 0.05 for the difference.

Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European Journal of Epidemiology, 31(4), 337–350. https://doi.org/10.1007/s10654-016-0149-3

&nbsp;

**Greenland and Poole 2010**
    
> **A valid way to interpret a confidence interval is to use its width as a measure of the precision of an  estimate. Precision refers to the degree to which an estimate may be affected by random error if the data and the model assumptions are correct. If the confidence interval is narrower, the estimate is more precise and there is less room for the play of chance.**

Greenland, S., & Poole, C. (2010). Problems in common interpretations of statistics in scientific articles, expert reports, and testimony. Jurimetrics. Retrieved from http://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/juraba51&section=10&casa_token=SDbCB9O5GpkAAAAA:UTMWcKFKUZMw490W5aBNZx73Ub9utiWk3Ky1418NZWnxLqoBClAS1kbqARCeCfid0F5ASKriJSqn

&nbsp;

**Modern epidemiology**

> If the underlying statistical model is correct and there is no bias, a confidence interval derived from a valid test will, over unlimited repetitions of the study, contain the true parameter with a frequency no less than its confidence level. This definition specifies the coverage property of the method used to generate the interval, not the probability that the true parameter value lies within the interval. For example, if the confidence level of a valid confidence interval is 90%, the frequency with which the interval will contain the true parameter will be at least 90%, if there is no bias. Consequently, under the assumed model for random variability (e.g., a binomial model, as described in Chapter 14) and with no bias, we should expect the confidence interval to include the true parameter value in at least 90% of replications of the process of obtaining the data. Unfortunately, this interpretation for the confidence interval is based on probability models and sampling properties that are seldom realized in epidemiologic studies; consequently, **it is preferable to view the confidence limits as only a rough estimate of the uncertainty in an epidemiologic result due to random error alone.** Even with this limited interpretation, the estimate depends on the correctness of the statistical model, which may be incorrect in many epidemiologic settings (Greenland, 1990).

> Furthermore, exact 95% confidence limits for the true rate ratio are 0.7–13. The fact that the null value (which, for the rate ratio, is 1.0) is within the interval tells us the outcome of the significance test: The estimate would not be statistically significant at the 1 - 0.95 = 0.05 alpha level. **The confidence limits, however, indicate that these data, although statistically compatible with no association, are even more compatible with a strong association — assuming that the statistical model used to construct the limits is correct.** Stating the latter assumption is important because confidence intervals, like P-values, do nothing to address biases that may be present.

> Indeed, because statistical hypothesis testing promotes so much misinterpretation, **we recommend avoiding its use in epidemiologic presentations and research reports.** Such avoidance requires that P-values (when used) be presented without reference to alpha levels or “statistical significance,” and that careful attention be paid to the confidence interval, especially its width and its endpoints (the confidence limits) (Altman et al., 2000; Poole, 2001c).

> An astute investigator may properly ask what frequency interpretations have to do with the single study under analysis. It is all very well to say that an interval estimation procedure will, in 95% of repetitions, produce limits that contain the true parameter. But in analyzing a given study, the relevant scientific question is this: **Does the single pair of limits produced from this one study contain the true parameter?** The ordinary (frequentist) theory of confidence intervals does not answer this question. The question is so important that many (perhaps most) users of confidence intervals mistakenly interpret the confidence level of the interval as the probability that the answer to the question is “yes.” It is quite tempting to say that the 95% confidence limits computed from a study contain the true parameter with 95% probability. Unfortunately, this interpretation can be correct only for Bayesian interval estimates (discussed later and in Chapter 18), which often diverge from ordinary confidence intervals.

Rothman, K. J., Greenland, S., & Lash, T. L. (2008). Modern epidemiology (Third). Philadelphia, PA: Lippincott Williams & Wilkins.

&nbsp;

**Statistical modeling: A fresh approach**

> Treat the confidence interval just as an indication of the precision of the measurement. If you do a study that finds a statistic of 17 ± 6 and someone else does a study that gives 23 ± 5, then there is little reason to think that the two studies are inconsistent. On the other hand, if your study gives 17 ± 2 and the other study is 23 ± 1, then something seems to be going on; you have a genuine disagreement on your hands.

Kaplan, D. T. (2017). Statistical modeling: A fresh approach (Second). Project MOSAIC Books.

&nbsp;

-------------------------------------------------------------------------------

# Examples from research


